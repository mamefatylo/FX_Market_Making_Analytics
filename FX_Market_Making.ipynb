{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a62ff29-670e-4912-a436-c882b3155c68",
   "metadata": {},
   "source": [
    "# FX Market Making Analytics Portfolio\n",
    "\n",
    "**Author**: Mame Faty Lo  \n",
    "**Purpose**: Showcase FX market analysis, data cleaning, visualization, and automation for major currency pairs relevant to Swissquote.  \n",
    "\n",
    "**Objectives**:\n",
    "- Load and clean FX market data.\n",
    "- Analyse **mid-price trends**, **bid-ask spreads**, **returns**, and **volatility**. \n",
    "- Simulate **market making strategies** and liquidity provision.\n",
    "- Generate **interactive charts and static visualisations** to support insights.\n",
    "\n",
    "**Notes**:\n",
    "- Data can be loaded from bundled sample CSVs or a snapshot pickle for convenience.\n",
    "- Volume, bid, and ask columns are included to mimic real FX market data.\n",
    "- All analysis is reproducible and ready for extension to live data sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36ca0e17-6549-4b22-ba00-cc6352c2c2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Scripts imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "# Set default Plotly template and size\n",
    "pio.templates.default = \"plotly_dark\"\n",
    "px.defaults.width = 900\n",
    "px.defaults.height = 520\n",
    "\n",
    "# Import our custom scripts\n",
    "from src import downloader_fx\n",
    "from src import data_loader\n",
    "from src import data_cleaner\n",
    "print(\"[INFO] Scripts imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1b3181-c874-4517-b0ea-62cf1ec3b146",
   "metadata": {},
   "source": [
    "# Download FX Data (1-Minute Bars)\n",
    "\n",
    "We download 1-minute FX data from **HistData.com** for selected currency pairs.  \n",
    "\n",
    "- Data will be saved as **one CSV per pair** in `data/raw/fx_full/`.  \n",
    "- Columns include: `DateTime`, `Open`, `High`, `Low`, `Close`, `Volume`.  \n",
    "- If the CSVs already exist, this step will skip downloading to save time.  \n",
    "- We fetch **3 months of historical data** as a snapshot for analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cd0a984-4491-4774-820d-d8c96848a350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] https://www.dukascopy.com/datafeed/EURUSD/2025/08/01/1min.csv not found (status 403)\n",
      "[WARN] https://www.dukascopy.com/datafeed/EURUSD/2025/08/02/1min.csv not found (status 403)\n",
      "[WARN] https://www.dukascopy.com/datafeed/EURUSD/2025/08/03/1min.csv not found (status 403)\n",
      "[WARN] https://www.dukascopy.com/datafeed/EURUSD/2025/08/04/1min.csv not found (status 403)\n",
      "[WARN] https://www.dukascopy.com/datafeed/EURUSD/2025/08/05/1min.csv not found (status 403)\n",
      "[WARN] https://www.dukascopy.com/datafeed/EURUSD/2025/08/06/1min.csv not found (status 403)\n",
      "[WARN] https://www.dukascopy.com/datafeed/EURUSD/2025/08/07/1min.csv not found (status 403)\n",
      "[WARN] https://www.dukascopy.com/datafeed/EURUSD/2025/08/08/1min.csv not found (status 403)\n",
      "[WARN] https://www.dukascopy.com/datafeed/EURUSD/2025/08/09/1min.csv not found (status 403)\n",
      "[WARN] https://www.dukascopy.com/datafeed/EURUSD/2025/08/10/1min.csv not found (status 403)\n",
      "[WARN] https://www.dukascopy.com/datafeed/EURUSD/2025/08/11/1min.csv not found (status 403)\n",
      "[WARN] https://www.dukascopy.com/datafeed/EURUSD/2025/08/12/1min.csv not found (status 403)\n",
      "[WARN] https://www.dukascopy.com/datafeed/EURUSD/2025/08/13/1min.csv not found (status 403)\n",
      "[WARN] https://www.dukascopy.com/datafeed/EURUSD/2025/08/14/1min.csv not found (status 403)\n",
      "[WARN] https://www.dukascopy.com/datafeed/EURUSD/2025/08/15/1min.csv not found (status 403)\n",
      "[WARN] https://www.dukascopy.com/datafeed/EURUSD/2025/08/16/1min.csv not found (status 403)\n",
      "[WARN] https://www.dukascopy.com/datafeed/EURUSD/2025/08/17/1min.csv not found (status 403)\n",
      "[WARN] https://www.dukascopy.com/datafeed/EURUSD/2025/08/18/1min.csv not found (status 403)\n",
      "[WARN] https://www.dukascopy.com/datafeed/EURUSD/2025/08/19/1min.csv not found (status 403)\n",
      "[WARN] https://www.dukascopy.com/datafeed/EURUSD/2025/08/20/1min.csv not found (status 403)\n",
      "[WARN] https://www.dukascopy.com/datafeed/EURUSD/2025/08/21/1min.csv not found (status 403)\n",
      "[WARN] https://www.dukascopy.com/datafeed/EURUSD/2025/08/22/1min.csv not found (status 403)\n",
      "[WARN] https://www.dukascopy.com/datafeed/EURUSD/2025/08/23/1min.csv not found (status 403)\n",
      "[WARN] https://www.dukascopy.com/datafeed/EURUSD/2025/08/24/1min.csv not found (status 403)\n",
      "[WARN] https://www.dukascopy.com/datafeed/EURUSD/2025/08/25/1min.csv not found (status 403)\n",
      "[WARN] https://www.dukascopy.com/datafeed/EURUSD/2025/08/26/1min.csv not found (status 403)\n",
      "[WARN] https://www.dukascopy.com/datafeed/EURUSD/2025/08/27/1min.csv not found (status 403)\n",
      "[WARN] https://www.dukascopy.com/datafeed/EURUSD/2025/08/28/1min.csv not found (status 403)\n",
      "[WARN] https://www.dukascopy.com/datafeed/EURUSD/2025/08/29/1min.csv not found (status 403)\n",
      "[WARN] https://www.dukascopy.com/datafeed/EURUSD/2025/08/30/1min.csv not found (status 403)\n",
      "[WARN] https://www.dukascopy.com/datafeed/EURUSD/2025/08/31/1min.csv not found (status 403)\n",
      "[WARN] https://www.dukascopy.com/datafeed/EURUSD/2025/09/01/1min.csv not found (status 403)\n",
      "[WARN] https://www.dukascopy.com/datafeed/EURUSD/2025/09/02/1min.csv not found (status 403)\n",
      "[WARN] https://www.dukascopy.com/datafeed/EURUSD/2025/09/03/1min.csv not found (status 403)\n",
      "[WARN] https://www.dukascopy.com/datafeed/EURUSD/2025/09/04/1min.csv not found (status 403)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Download each pair\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m pair \u001b[38;5;129;01min\u001b[39;00m fx_pairs:\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     downloader_fx.download_and_combine_fx(pair, start_date, end_date, save_path=\u001b[33m\"\u001b[39m\u001b[33mdata/raw\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Career/Data Analyst Projects/fx_market_making_analytics/src/downloader_fx.py:43\u001b[39m, in \u001b[36mdownload_and_combine_fx\u001b[39m\u001b[34m(pair, start_date, end_date, save_path)\u001b[39m\n\u001b[32m     40\u001b[39m file_url = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mhttps://www.dukascopy.com/datafeed/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpair\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl_date\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/1min.csv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     r = requests.get(file_url)\n\u001b[32m     44\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m r.status_code == \u001b[32m200\u001b[39m:\n\u001b[32m     45\u001b[39m         \u001b[38;5;66;03m# Read CSV directly from content\u001b[39;00m\n\u001b[32m     46\u001b[39m         \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StringIO\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/fx_env/lib/python3.11/site-packages/requests/api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(url, params=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[33m\"\u001b[39m\u001b[33mget\u001b[39m\u001b[33m\"\u001b[39m, url, params=params, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/fx_env/lib/python3.11/site-packages/requests/api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m session.request(method=method, url=url, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/fx_env/lib/python3.11/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28mself\u001b[39m.send(prep, **send_kwargs)\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/fx_env/lib/python3.11/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = adapter.send(request, **kwargs)\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/fx_env/lib/python3.11/site-packages/requests/adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    664\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = conn.urlopen(\n\u001b[32m    668\u001b[39m         method=request.method,\n\u001b[32m    669\u001b[39m         url=url,\n\u001b[32m    670\u001b[39m         body=request.body,\n\u001b[32m    671\u001b[39m         headers=request.headers,\n\u001b[32m    672\u001b[39m         redirect=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    673\u001b[39m         assert_same_host=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    674\u001b[39m         preload_content=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    675\u001b[39m         decode_content=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    676\u001b[39m         retries=\u001b[38;5;28mself\u001b[39m.max_retries,\n\u001b[32m    677\u001b[39m         timeout=timeout,\n\u001b[32m    678\u001b[39m         chunked=chunked,\n\u001b[32m    679\u001b[39m     )\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    682\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/fx_env/lib/python3.11/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28mself\u001b[39m._make_request(\n\u001b[32m    788\u001b[39m     conn,\n\u001b[32m    789\u001b[39m     method,\n\u001b[32m    790\u001b[39m     url,\n\u001b[32m    791\u001b[39m     timeout=timeout_obj,\n\u001b[32m    792\u001b[39m     body=body,\n\u001b[32m    793\u001b[39m     headers=headers,\n\u001b[32m    794\u001b[39m     chunked=chunked,\n\u001b[32m    795\u001b[39m     retries=retries,\n\u001b[32m    796\u001b[39m     response_conn=response_conn,\n\u001b[32m    797\u001b[39m     preload_content=preload_content,\n\u001b[32m    798\u001b[39m     decode_content=decode_content,\n\u001b[32m    799\u001b[39m     **response_kw,\n\u001b[32m    800\u001b[39m )\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/fx_env/lib/python3.11/site-packages/urllib3/connectionpool.py:464\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    462\u001b[39m     \u001b[38;5;66;03m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[32m    463\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m         \u001b[38;5;28mself\u001b[39m._validate_conn(conn)\n\u001b[32m    465\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    466\u001b[39m         \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=conn.timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/fx_env/lib/python3.11/site-packages/urllib3/connectionpool.py:1093\u001b[39m, in \u001b[36mHTTPSConnectionPool._validate_conn\u001b[39m\u001b[34m(self, conn)\u001b[39m\n\u001b[32m   1091\u001b[39m \u001b[38;5;66;03m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[32m   1092\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m conn.is_closed:\n\u001b[32m-> \u001b[39m\u001b[32m1093\u001b[39m     conn.connect()\n\u001b[32m   1095\u001b[39m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n\u001b[32m   1096\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn.is_verified \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn.proxy_is_verified:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/fx_env/lib/python3.11/site-packages/urllib3/connection.py:753\u001b[39m, in \u001b[36mHTTPSConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    751\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    752\u001b[39m     sock: socket.socket | ssl.SSLSocket\n\u001b[32m--> \u001b[39m\u001b[32m753\u001b[39m     \u001b[38;5;28mself\u001b[39m.sock = sock = \u001b[38;5;28mself\u001b[39m._new_conn()\n\u001b[32m    754\u001b[39m     server_hostname: \u001b[38;5;28mstr\u001b[39m = \u001b[38;5;28mself\u001b[39m.host\n\u001b[32m    755\u001b[39m     tls_in_tls = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/fx_env/lib/python3.11/site-packages/urllib3/connection.py:198\u001b[39m, in \u001b[36mHTTPConnection._new_conn\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    193\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Establish a socket connection and set nodelay settings on it.\u001b[39;00m\n\u001b[32m    194\u001b[39m \n\u001b[32m    195\u001b[39m \u001b[33;03m:return: New socket connection.\u001b[39;00m\n\u001b[32m    196\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m     sock = connection.create_connection(\n\u001b[32m    199\u001b[39m         (\u001b[38;5;28mself\u001b[39m._dns_host, \u001b[38;5;28mself\u001b[39m.port),\n\u001b[32m    200\u001b[39m         \u001b[38;5;28mself\u001b[39m.timeout,\n\u001b[32m    201\u001b[39m         source_address=\u001b[38;5;28mself\u001b[39m.source_address,\n\u001b[32m    202\u001b[39m         socket_options=\u001b[38;5;28mself\u001b[39m.socket_options,\n\u001b[32m    203\u001b[39m     )\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m socket.gaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    205\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NameResolutionError(\u001b[38;5;28mself\u001b[39m.host, \u001b[38;5;28mself\u001b[39m, e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/fx_env/lib/python3.11/site-packages/urllib3/util/connection.py:73\u001b[39m, in \u001b[36mcreate_connection\u001b[39m\u001b[34m(address, timeout, source_address, socket_options)\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m source_address:\n\u001b[32m     72\u001b[39m     sock.bind(source_address)\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m sock.connect(sa)\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n\u001b[32m     75\u001b[39m err = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Step 1: Download FX data using our custom downloader\n",
    "\n",
    "from datetime import date\n",
    "\n",
    "# Pairs and date range\n",
    "fx_pairs = [\"EURUSD\", \"USDCHF\", \"GBPUSD\"]\n",
    "start_date = date(2025, 8, 1)\n",
    "end_date = date(2025, 10, 28)  # adjust as needed\n",
    "\n",
    "# Download each pair\n",
    "for pair in fx_pairs:\n",
    "    downloader_fx.download_and_combine_fx(pair, start_date, end_date, save_path=\"data/raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e63a9f6c-4a84-4ad0-a66a-820c5770a266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No CSV or snapshot found for EUR_USD, skipping\n",
      "[WARNING] No CSV or snapshot found for USD_CHF, skipping\n",
      "[WARNING] No CSV or snapshot found for GBP_USD, skipping\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# FX Data Loader\n",
    "# -------------------------\n",
    "def load_fx_data(pairs, raw_path=raw_path, snapshot_path=snapshots_path):\n",
    "    \"\"\"\n",
    "    Load FX data for multiple currency pairs.\n",
    "\n",
    "    Priority:\n",
    "    1) Load raw CSVs from raw_path if available.\n",
    "    2) Else load minimal bundled snapshot (pickle).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pairs : list of str\n",
    "        e.g., [\"EUR_USD\", \"USD_CHF\"]\n",
    "    raw_path : Path\n",
    "        Folder containing raw CSV files\n",
    "    snapshot_path : Path\n",
    "        Folder containing bundled snapshot pickle\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    fx_data : dict\n",
    "        {pair_name: DataFrame}\n",
    "    \"\"\"\n",
    "    fx_data = {}\n",
    "\n",
    "    for pair in pairs:\n",
    "        csv_file = raw_path / f\"{pair}.csv\"\n",
    "        if csv_file.exists():\n",
    "            df = pd.read_csv(csv_file)\n",
    "            print(f\"[INFO] Loaded {pair} from CSV: {len(df)} rows\")\n",
    "        else:\n",
    "            # fallback to snapshot pickle\n",
    "            snapshot_file = snapshot_path / f\"{pair}_snapshot.pkl\"\n",
    "            if snapshot_file.exists():\n",
    "                df = pd.read_pickle(snapshot_file)\n",
    "                print(f\"[INFO] Loaded {pair} from bundled snapshot: {len(df)} rows\")\n",
    "            else:\n",
    "                print(f\"[WARNING] No CSV or snapshot found for {pair}, skipping\")\n",
    "                continue\n",
    "        # Convert date column if present\n",
    "        if \"Date\" in df.columns:\n",
    "            df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
    "        # Ensure numeric columns\n",
    "        for col in [\"Price\", \"Open\", \"High\", \"Low\", \"Volume\"]:\n",
    "            if col in df.columns:\n",
    "                df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "        fx_data[pair] = df\n",
    "\n",
    "    return fx_data\n",
    "\n",
    "# -------------------------\n",
    "# Example usage\n",
    "# -------------------------\n",
    "pairs = [\"EUR_USD\", \"USD_CHF\", \"GBP_USD\"]\n",
    "fx_data = load_fx_data(pairs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db458bed-964f-4b90-b406-61fd3d5d7402",
   "metadata": {},
   "source": [
    "## Load API Keys from Environment Variables\n",
    "\n",
    "We keep API credentials separate from the notebook for security and reproducibility. This cell loads your OANDA (FX) and Binance (Digital Assets) API keys from the `.env` file located in the `env/` folder at the project root. Keys will be stored in variables for subsequent data fetching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "813f7320-1352-43be-a8fb-74935c98a45d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'download_and_combine_fx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m date\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m download_and_combine_fx(\u001b[33m\"\u001b[39m\u001b[33mEURUSD\u001b[39m\u001b[33m\"\u001b[39m, date(\u001b[32m2025\u001b[39m, \u001b[32m8\u001b[39m, \u001b[32m1\u001b[39m), date(\u001b[32m2025\u001b[39m, \u001b[32m10\u001b[39m, \u001b[32m28\u001b[39m))\n",
      "\u001b[31mNameError\u001b[39m: name 'download_and_combine_fx' is not defined"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "download_and_combine_fx(\"EURUSD\", date(2025, 8, 1), date(2025, 10, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b7b740-3604-46a6-b6ce-1b932199258c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Info for each FX pair\n",
    "for pair_name, df in cleaned_fx_data.items():\n",
    "    print(f\"=== {pair_name} ===\")\n",
    "    df.info()\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Descriptive stats (excluding 'Date')\n",
    "for pair_name, df in cleaned_fx_data.items():\n",
    "    print(f\"=== {pair_name} ===\")\n",
    "    display(df[numeric_cols].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a926cb7b-686f-4f0f-8942-fdca62124b78",
   "metadata": {},
   "source": [
    "## FX Market Analysis\n",
    "\n",
    "### Basic Descriptive Statistics\n",
    "\n",
    "Quick descriptive statistics for numeric columns (`Open`, `High`, `Low`, `Price`, `Change %`) across all FX pairs. This helps inspect ranges, averages, and variability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dc4961-01be-4922-8478-231c554f46f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
    "print(\"Missing dates:\", df[\"Date\"].isna().sum())\n",
    "\n",
    "for col in numeric_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "        print(f\"Missing in {col}:\", df[col].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3feb8d-0d9c-4636-bf1c-fc5c92e843d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "141a3d82-2c35-4d2e-ba6d-f6ce5da109af",
   "metadata": {},
   "source": [
    "### Price Trends (Normalised)\n",
    "\n",
    "**Purpose:** Compare relative price movements across FX pairs that have very different scales.\n",
    "\n",
    "**Method:** We normalise each pair by its price at the first available date:\n",
    "\n",
    "$$\n",
    "\\text{Normalised Price}_t = \\frac{\\text{Price}_t}{\\text{Price}_{t_0}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $t_0$ is the first available date for the FX pair.\n",
    "- $\\text{Price}_t$ is the price at time $t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b14c445c-7521-4ad8-8605-4307d584b5ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cleaned_fx_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Concatenate all cleaned pairs into a single dataframe\u001b[39;00m\n\u001b[32m      2\u001b[39m plot_df = pd.concat(\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     (df.assign(Pair=pair) \u001b[38;5;28;01mfor\u001b[39;00m pair, df \u001b[38;5;129;01min\u001b[39;00m cleaned_fx_data.items()),\n\u001b[32m      4\u001b[39m     ignore_index=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m      5\u001b[39m )\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Ensure 'Date' column is datetime\u001b[39;00m\n\u001b[32m      8\u001b[39m plot_df[\u001b[33m\"\u001b[39m\u001b[33mDate\u001b[39m\u001b[33m\"\u001b[39m] = pd.to_datetime(plot_df[\u001b[33m\"\u001b[39m\u001b[33mDate\u001b[39m\u001b[33m\"\u001b[39m], errors=\u001b[33m\"\u001b[39m\u001b[33mcoerce\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'cleaned_fx_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Concatenate all cleaned pairs into a single dataframe\n",
    "plot_df = pd.concat(\n",
    "    (df.assign(Pair=pair) for pair, df in cleaned_fx_data.items()),\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "# Ensure 'Date' column is datetime\n",
    "plot_df[\"Date\"] = pd.to_datetime(plot_df[\"Date\"], errors=\"coerce\")\n",
    "\n",
    "# 3) Convert numeric columns to float\n",
    "numeric_cols_existing = [c for c in numeric_cols if c in plot_df.columns]\n",
    "plot_df[numeric_cols_existing] = plot_df[numeric_cols_existing].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "# 4) Drop rows with missing Date, Price, or Pair, then sort\n",
    "plot_df = plot_df.dropna(subset=[\"Date\", \"Price\", \"Pair\"]).sort_values([\"Pair\", \"Date\"]).reset_index(drop=True)\n",
    "\n",
    "# 5) Compute normalised price per pair (base = first available price)\n",
    "plot_df[\"Normalised Price\"] = plot_df.groupby(\"Pair\")[\"Price\"].transform(lambda x: x / x.iloc[0])\n",
    "\n",
    "# 6) Quick check: number of points per pair & preview\n",
    "print(\"Points per pair:\\n\", plot_df[\"Pair\"].value_counts(), \"\\n\")\n",
    "display(plot_df.loc[:, [\"Pair\", \"Date\", \"Price\", \"Normalised Price\"]].head(8))\n",
    "\n",
    "# 7) Interactive Plotly line chart\n",
    "fig = px.line(\n",
    "    plot_df,\n",
    "    x=\"Date\",\n",
    "    y=\"Normalised Price\",\n",
    "    color=\"Pair\",\n",
    "    title=\"Normalised FX Price Trends (base = first available price)\",\n",
    "    labels={\n",
    "        \"Normalised Price\": \"Normalised Price (base = 1)\",\n",
    "        \"Date\": \"Date\",\n",
    "        \"Pair\": \"Currency Pair\"\n",
    "    },\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    template=\"plotly_dark\",\n",
    "    legend_title_text=\"Currency Pair\",\n",
    "    width=960,\n",
    "    height=520,\n",
    "    hovermode=\"x unified\",\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62b33f1-d6e9-479e-a2b9-6fca344e161f",
   "metadata": {},
   "source": [
    "- All pairs start at 1, enabling direct visual comparison of relative price movements.\n",
    "- Hover over lines to see exact normalised values and dates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1910ea29-b441-4e9a-ae6f-934b4ebc11ea",
   "metadata": {},
   "source": [
    "## Daily Returns and Volatility\n",
    "\n",
    "**Purpose**:  \n",
    "Assess the day-to-day price changes and the risk (volatility) associated with each FX pair. This helps understand market behaviour and identify periods of high or low activity.\n",
    "\n",
    "**Method**:  \n",
    "\n",
    "1. **Daily Returns**: The percentage change in FX price from one day to the next:  \n",
    "\n",
    "$$\n",
    "R_t = \\frac{P_t - P_{t-1}}{P_{t-1}} \\times 100\n",
    "$$\n",
    "\n",
    "Where:  \n",
    "- \\(R_t\\) = daily return at day \\(t\\)  \n",
    "- \\(P_t\\) = FX price at day \\(t\\)  \n",
    "- \\(P_{t-1}\\) = FX price at day \\(t-1\\)  \n",
    "\n",
    "2. **Volatility**: Standard deviation of daily returns over a period \\(n\\):  \n",
    "\n",
    "$$\n",
    "\\text{Volatility}_t = \\sqrt{\\frac{1}{n-1} \\sum_{i=0}^{n-1} (R_{t-i} - \\bar{R})^2}\n",
    "$$\n",
    "\n",
    "Where:  \n",
    "- \\(R_{t-i}\\) = daily return on day \\(t-i\\)  \n",
    "- \\(\\bar{R}\\) = mean daily return over \\(n\\) days  \n",
    "\n",
    "**Highlight**:  \n",
    "- Use an interactive Plotly line chart to visualise returns over time.  \n",
    "- Volatility can be plotted as a rolling standard deviation to show periods of higher risk.  \n",
    "- Colour-code FX pairs for clarity and hover labels for exact values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502161b7-c4db-4fe5-9b93-74ca864f5d88",
   "metadata": {},
   "source": [
    "## Daily Returns and Volatility\n",
    "\n",
    "**Purpose**:  \n",
    "Assess the day-to-day price changes and the risk (volatility) associated with each FX pair. This helps understand market behaviour and identify periods of high or low activity.\n",
    "\n",
    "**Method**:  \n",
    "\n",
    "1. **Daily Returns**: The percentage change in FX price from one day to the next:  \n",
    "\n",
    "$$\n",
    "R_t = \\frac{P_t - P_{t-1}}{P_{t-1}} \\times 100\n",
    "$$\n",
    "\n",
    "Where:  \n",
    "- \\(R_t\\) = daily return at day \\(t\\)  \n",
    "- \\(P_t\\) = FX price at day \\(t\\)  \n",
    "- \\(P_{t-1}\\) = FX price at day \\(t-1\\)  \n",
    "\n",
    "2. **Volatility**: Standard deviation of daily returns over a period \\(n\\):  \n",
    "\n",
    "$$\n",
    "\\text{Volatility}_t = \\sqrt{\\frac{1}{n-1} \\sum_{i=0}^{n-1} (R_{t-i} - \\bar{R})^2}\n",
    "$$\n",
    "\n",
    "Where:  \n",
    "- \\(R_{t-i}\\) = daily return on day \\(t-i\\)  \n",
    "- \\(\\bar{R}\\) = mean daily return over \\(n\\) days  \n",
    "\n",
    "**Highlight**:  \n",
    "- Use an interactive Plotly line chart to visualise returns over time.  \n",
    "- Volatility can be plotted as a rolling standard deviation to show periods of higher risk.  \n",
    "- Colour-code FX pairs for clarity and hover labels for exact values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3b9f58-6e1c-43a5-a5be-87cb901be6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Compute daily returns and rolling volatility ---\n",
    "\n",
    "returns_df = pd.DataFrame()\n",
    "\n",
    "for pair, df in cleaned_fx_data.items():\n",
    "    temp = df.copy()\n",
    "    temp[\"Daily Return %\"] = temp[\"Price\"].pct_change() * 100\n",
    "    temp[\"Volatility (5-day rolling %)\"] = temp[\"Daily Return %\"].rolling(window=5).std()\n",
    "    temp[\"Pair\"] = pair\n",
    "    returns_df = pd.concat([returns_df, temp], ignore_index=True)\n",
    "\n",
    "# Drop first row of each pair (NaN return)\n",
    "returns_df.dropna(subset=[\"Daily Return %\"], inplace=True)\n",
    "\n",
    "# Interactive Plotly line chart for daily returns\n",
    "fig_returns = px.line(\n",
    "    returns_df,\n",
    "    x=\"Date\",\n",
    "    y=\"Daily Return %\",\n",
    "    color=\"Pair\",\n",
    "    title=\"Daily Returns for Major FX Pairs\",\n",
    "    labels={\"Daily Return %\": \"Daily Return (%)\", \"Date\": \"Date\", \"Pair\": \"Currency Pair\"}\n",
    ")\n",
    "fig_returns.update_layout(template=\"plotly_dark\", hovermode=\"x unified\")\n",
    "fig_returns.show()\n",
    "\n",
    "# Optional: Plot rolling volatility\n",
    "fig_vol = px.line(\n",
    "    returns_df,\n",
    "    x=\"Date\",\n",
    "    y=\"Volatility (5-day rolling %)\",\n",
    "    color=\"Pair\",\n",
    "    title=\"Rolling 5-Day Volatility of FX Pairs\",\n",
    "    labels={\"Volatility (5-day rolling %)\": \"Volatility (%)\", \"Date\": \"Date\", \"Pair\": \"Currency Pair\"}\n",
    ")\n",
    "fig_vol.update_layout(template=\"plotly_dark\", hovermode=\"x unified\")\n",
    "fig_vol.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6198b868-8a15-4e17-b89a-e0de99caa05d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
